{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSION INFRARED DATASET"
      ],
      "metadata": {
        "id": "JyDScD94Crht"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWjRB1cif12c",
        "outputId": "ff995a7c-1aa9-414d-950b-b5f72e3b5d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-0b3daf761dd7>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 180.9966\n",
            "Epoch [20/50], Loss: 12.3951\n",
            "Epoch [30/50], Loss: 4.9354\n",
            "Epoch [40/50], Loss: 2.6665\n",
            "Epoch [50/50], Loss: 1.7335\n",
            "\n",
            "Evaluasi Model:\n",
            "Mean Squared Error (MSE): 2.9286\n",
            "Root Mean Squared Error (RMSE): 1.7113\n",
            "R-Squared (RÂ²): -9.7971\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Cek apakah CUDA tersedia\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Infrared.csv\")\n",
        "\n",
        "# Mengisi nilai yang hilang dengan median\n",
        "df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
        "\n",
        "# Encoding variabel kategorikal\n",
        "label_encoders = {}\n",
        "categorical_cols = [\"Gender\", \"Age\", \"Ethnicity\"]\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = df.columns.difference([\"aveOralM\"])  # Semua fitur kecuali target\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X = torch.tensor(df[numerical_cols].values, dtype=torch.float32).to(device)\n",
        "y = torch.tensor(df[\"aveOralM\"].values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Membagi data menjadi training (80%) dan testing (20%)\n",
        "train_size = int(0.8 * len(df))\n",
        "test_size = len(df) - train_size\n",
        "dataset = TensorDataset(X, y)\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Membuat DataLoader untuk batch processing\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Definisi model Deep Learning\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Inisialisasi model, loss function, dan optimizer\n",
        "input_size = X.shape[1]\n",
        "model = NeuralNet(input_size).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training model\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Print setiap 10 epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluasi model\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        predictions = model(batch_X)\n",
        "        y_true.extend(batch_y.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\nEvaluasi Model:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-Squared (RÂ²): {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Infrared.csv\")\n",
        "\n",
        "# Mengisi nilai yang hilang dengan median\n",
        "df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
        "\n",
        "# Encoding variabel kategorikal\n",
        "label_encoders = {}\n",
        "categorical_cols = [\"Gender\", \"Age\", \"Ethnicity\"]\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = df.columns.difference([\"aveOralM\"])  # Semua fitur kecuali target\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X = df[numerical_cols].values\n",
        "y = df[\"aveOralM\"].values\n",
        "\n",
        "# Membagi data menjadi training (80%) dan testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membangun model dengan TensorFlow (Keras)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # Output layer untuk regresi\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n",
        "\n",
        "# Training model\n",
        "num_epochs = 50\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluasi model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nEvaluasi Model:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-Squared (RÂ²): {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdYAkkKgX5yi",
        "outputId": "ba411131-fc10-435e-ea7f-0927c0815130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e76f142cd14d>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1352.0593 - mse: 1352.0593 - val_loss: 1236.2085 - val_mse: 1236.2085\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1173.6807 - mse: 1173.6807 - val_loss: 983.8384 - val_mse: 983.8384\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 915.6106 - mse: 915.6106 - val_loss: 627.9178 - val_mse: 627.9178\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603.3255 - mse: 603.3255 - val_loss: 474.0075 - val_mse: 474.0075\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476.3400 - mse: 476.3400 - val_loss: 459.0061 - val_mse: 459.0061\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 441.5398 - mse: 441.5398 - val_loss: 397.2764 - val_mse: 397.2764\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 368.5170 - mse: 368.5170 - val_loss: 342.1775 - val_mse: 342.1775\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 299.7586 - mse: 299.7586 - val_loss: 273.5806 - val_mse: 273.5806\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 239.8593 - mse: 239.8593 - val_loss: 213.6297 - val_mse: 213.6297\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179.9853 - mse: 179.9853 - val_loss: 172.7796 - val_mse: 172.7796\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131.8212 - mse: 131.8212 - val_loss: 133.8642 - val_mse: 133.8642\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94.0109 - mse: 94.0109 - val_loss: 98.3987 - val_mse: 98.3987\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 67.8378 - mse: 67.8378 - val_loss: 81.1222 - val_mse: 81.1222\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.8635 - mse: 48.8635 - val_loss: 67.4974 - val_mse: 67.4974\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.5934 - mse: 36.5934 - val_loss: 57.1703 - val_mse: 57.1703\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7996 - mse: 29.7996 - val_loss: 48.5748 - val_mse: 48.5748\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4063 - mse: 27.4063 - val_loss: 43.6308 - val_mse: 43.6308\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.5166 - mse: 22.5166 - val_loss: 39.0458 - val_mse: 39.0458\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.4456 - mse: 20.4456 - val_loss: 35.3697 - val_mse: 35.3697\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19.2850 - mse: 19.2850 - val_loss: 31.2286 - val_mse: 31.2286\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2167 - mse: 16.2167 - val_loss: 29.7012 - val_mse: 29.7012\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.5957 - mse: 15.5957 - val_loss: 26.7366 - val_mse: 26.7366\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.0641 - mse: 14.0641 - val_loss: 24.2799 - val_mse: 24.2799\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.0433 - mse: 13.0433 - val_loss: 22.1594 - val_mse: 22.1594\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.0744 - mse: 12.0744 - val_loss: 21.4208 - val_mse: 21.4208\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.6800 - mse: 11.6800 - val_loss: 19.5321 - val_mse: 19.5321\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3621 - mse: 10.3621 - val_loss: 18.0701 - val_mse: 18.0701\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.2544 - mse: 10.2544 - val_loss: 17.5997 - val_mse: 17.5997\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4199 - mse: 9.4199 - val_loss: 16.5474 - val_mse: 16.5474\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2042 - mse: 8.2042 - val_loss: 15.5372 - val_mse: 15.5372\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7140 - mse: 7.7140 - val_loss: 14.3928 - val_mse: 14.3928\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5602 - mse: 7.5602 - val_loss: 13.8642 - val_mse: 13.8642\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1339 - mse: 7.1339 - val_loss: 13.1419 - val_mse: 13.1419\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8358 - mse: 6.8358 - val_loss: 12.3586 - val_mse: 12.3586\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5849 - mse: 6.5849 - val_loss: 11.6115 - val_mse: 11.6115\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4249 - mse: 6.4249 - val_loss: 11.2511 - val_mse: 11.2511\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3865 - mse: 5.3865 - val_loss: 10.8945 - val_mse: 10.8945\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8904 - mse: 5.8904 - val_loss: 10.1360 - val_mse: 10.1360\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0205 - mse: 5.0205 - val_loss: 9.9144 - val_mse: 9.9144\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6848 - mse: 4.6848 - val_loss: 9.4696 - val_mse: 9.4696\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1039 - mse: 5.1039 - val_loss: 9.0090 - val_mse: 9.0090\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.0402 - mse: 4.0402 - val_loss: 8.7949 - val_mse: 8.7949\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5846 - mse: 4.5846 - val_loss: 8.1697 - val_mse: 8.1697\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5209 - mse: 4.5209 - val_loss: 8.0087 - val_mse: 8.0087\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9043 - mse: 3.9043 - val_loss: 7.5973 - val_mse: 7.5973\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8576 - mse: 3.8576 - val_loss: 7.3136 - val_mse: 7.3136\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8266 - mse: 3.8266 - val_loss: 7.3324 - val_mse: 7.3324\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7013 - mse: 3.7013 - val_loss: 6.8158 - val_mse: 6.8158\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3440 - mse: 3.3440 - val_loss: 6.6798 - val_mse: 6.6798\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1625 - mse: 3.1625 - val_loss: 6.2900 - val_mse: 6.2900\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\n",
            "Evaluasi Model:\n",
            "Mean Squared Error (MSE): 5.0543\n",
            "Root Mean Squared Error (RMSE): 2.2482\n",
            "R-Squared (RÂ²): -23.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Regression Infrared: Regresi Linear\n",
        "\n",
        "### Persamaan Model\n",
        "$$\n",
        "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
        "$$\n",
        "\n",
        "**$$\\hat{y}$$** Merupakan nilai prediksi dari model. Ini adalah nilai yang diharapkan (diperkirakan) berdasarkan kombinasi linier dari fitur-fitur.\n",
        "  \n",
        "**$$x_1, x_2, \\dots, x_n\\$$** Merupakan fitur-fitur (variabel independen) yang digunakan untuk memprediksi nilai target. Misalnya, pada dataset Automobile, fitur bisa berupa atribut mobil seperti harga, berat, atau ukuran mesin.\n",
        "  \n",
        "**$$\\beta_0\\$$** Adalah intercept (konstanta), yaitu nilai yang diprediksi ketika semua fitur bernilai nol. Ini merupakan titik awal dari garis prediksi.\n",
        "  \n",
        "**$$\\beta_1, \\beta_2, \\dots, \\beta_n\\$$** Adalah koefisien yang menunjukkan seberapa besar pengaruh masing-masing fitur terhadap prediksi. Nilai koefisien ini menentukan kemiringan atau â€œgradienâ€ dari garis yang membentuk model.\n",
        "\n",
        "### Fungsi Cost (Least Squares)\n",
        "$$\n",
        "J(\\beta) = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "- **$$y_i\\$$** Nilai aktual (observasi) dari target untuk sampel ke-\\(i\\).\n",
        "  \n",
        "- **$$\\hat{y}_i\\$$** Nilai prediksi model untuk sampel ke-\\(i\\).\n",
        "  \n",
        "- **$$n\\$$** Jumlah total sampel dalam dataset.\n",
        "  \n",
        "- **$$J(\\beta)\\$$** Merupakan fungsi cost yang mengukur rata-rata kesalahan kuadrat antara nilai aktual dan prediksi. Metode Least Squares berusaha menemukan nilai parameter \\(\\beta\\) yang meminimalkan fungsi ini sehingga prediksi model sedekat mungkin dengan nilai nyata.\n",
        "\n",
        "### Metrik Evaluasi\n",
        "- **Mean Squared Error (MSE):**\n",
        "  $$\n",
        "  \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
        "  $$\n",
        "  MSE mengukur seberapa besar rata-rata kesalahan kuadrat antara nilai prediksi dan aktual; semakin kecil MSE, semakin baik model dalam memprediksi data.\n",
        "  \n",
        "- **Root Mean Squared Error (RMSE):**\n",
        "  $$\n",
        "  \\text{RMSE} = \\sqrt{\\text{MSE}}\n",
        "  $$\n",
        "  RMSE memberikan kesalahan prediksi dalam satuan yang sama dengan target, sehingga lebih mudah diinterpretasikan.\n",
        "  \n",
        "- **R-squared (RÂ²):**\n",
        "  $$\n",
        "  R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n",
        "  $$\n",
        "  \\(R^2\\) mengukur proporsi variansi data yang dapat dijelaskan oleh model. Nilai yang mendekati 1 berarti model mampu menjelaskan sebagian besar variansi data, sedangkan nilai yang rendah menunjukkan model kurang baik.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jfO0LurVDIdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASSIFICATION INCOME"
      ],
      "metadata": {
        "id": "10zxelsdCz5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£ Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 2ï¸âƒ£ Load Dataset (Keep NaN)\n",
        "file_path = \"/content/income (1).csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove extra spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Convert target 'income' to 0 and 1\n",
        "df[\"income\"] = df[\"income\"].str.strip()\n",
        "df[\"income\"] = df[\"income\"].map({\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "# Encode categorical features\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Split dataset\n",
        "X = df.drop(columns=[\"income\"])\n",
        "y = df[\"income\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data (Keep NaN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# =====================================\n",
        "# ğŸŸ¢  PyTorch Section ğŸŸ¢\n",
        "# =====================================\n",
        "\n",
        "# Convert to PyTorch Tensors (Keep NaN but handle it for training)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Replace NaN in tensors with zeros for training\n",
        "X_train_tensor = torch.nan_to_num(X_train_tensor, nan=0.0)\n",
        "y_train_tensor = torch.nan_to_num(y_train_tensor, nan=0.0)\n",
        "\n",
        "# Define PyTorch Model\n",
        "class IncomeModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IncomeModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize PyTorch Model (Ensure float32)\n",
        "model = IncomeModel().float()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training PyTorch Model (Ignore NaN in Loss)\n",
        "print(\"\\nğŸŸ¢ Training PyTorch Model...\")\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)  # Ensure float32\n",
        "\n",
        "    # Clamp outputs to prevent log(0) issue\n",
        "    outputs = torch.clamp(outputs, min=1e-7, max=1 - 1e-7)\n",
        "\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Ignore NaN values in loss\n",
        "    if torch.isnan(loss):\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss contains NaN, replacing with 0.0\")\n",
        "        loss = torch.nan_to_num(loss, nan=0.0)\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], PyTorch Loss: {loss.item():.6f}\")\n",
        "\n",
        "# Evaluate PyTorch Model\n",
        "y_pred_tensor = torch.sigmoid(model(X_test_tensor)).detach().numpy()\n",
        "y_pred_pytorch = (y_pred_tensor > 0.5).astype(int)\n",
        "\n",
        "# =====================================\n",
        "# ğŸ”µ  TensorFlow (Keras) Section ğŸ”µ\n",
        "# =====================================\n",
        "\n",
        "# Define TensorFlow Model\n",
        "model_tf = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile TensorFlow Model\n",
        "model_tf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Custom Callback to Handle NaN Loss in TensorFlow\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if np.isnan(logs[\"loss\"]):\n",
        "            print(f\"Epoch [{epoch+1}] - Loss is NaN, replacing with 0.0\")\n",
        "            logs[\"loss\"] = 0.0\n",
        "        if \"val_loss\" in logs and np.isnan(logs[\"val_loss\"]):\n",
        "            print(f\"Epoch [{epoch+1}] - Val Loss is NaN, replacing with 0.0\")\n",
        "            logs[\"val_loss\"] = 0.0\n",
        "\n",
        "# Train TensorFlow Model\n",
        "print(\"\\nğŸ”µ Training TensorFlow Model...\")\n",
        "model_tf.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=[CustomCallback()])\n",
        "\n",
        "# Evaluate TensorFlow Model\n",
        "y_pred_tf = (model_tf.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# =====================================\n",
        "# ğŸ“Š Model Evaluation (Fix NaN in y_test)\n",
        "# =====================================\n",
        "\n",
        "# âœ… Fix NaN in y_test before evaluation\n",
        "y_test_clean = y_test.dropna().reset_index(drop=True)\n",
        "y_pred_pytorch_clean = y_pred_pytorch[:len(y_test_clean)]\n",
        "y_pred_tf_clean = y_pred_tf[:len(y_test_clean)]\n",
        "\n",
        "# Calculate Metrics for Both Models\n",
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
        "scores_pytorch = [\n",
        "    accuracy_score(y_test_clean, y_pred_pytorch_clean),\n",
        "    precision_score(y_test_clean, y_pred_pytorch_clean),\n",
        "    recall_score(y_test_clean, y_pred_pytorch_clean),\n",
        "    f1_score(y_test_clean, y_pred_pytorch_clean)\n",
        "]\n",
        "\n",
        "scores_tf = [\n",
        "    accuracy_score(y_test_clean, y_pred_tf_clean),\n",
        "    precision_score(y_test_clean, y_pred_tf_clean),\n",
        "    recall_score(y_test_clean, y_pred_tf_clean),\n",
        "    f1_score(y_test_clean, y_pred_tf_clean)\n",
        "]\n",
        "\n",
        "# Print Results\n",
        "print(\"\\n===============================\")\n",
        "print(\"ğŸ“Š Model Performance Comparison\")\n",
        "print(\"===============================\")\n",
        "\n",
        "for i in range(len(metrics)):\n",
        "    print(f\"{metrics[i]}:\")\n",
        "    print(f\"  ğŸŸ¢ PyTorch: {scores_pytorch[i]:.4f}\")\n",
        "    print(f\"  ğŸ”µ TensorFlow: {scores_tf[i]:.4f}\")\n",
        "    print()\n",
        "\n",
        "# Determine Best Model\n",
        "better_model = \"PyTorch\" if np.mean(scores_pytorch) > np.mean(scores_tf) else \"TensorFlow\"\n",
        "print(f\"\\nğŸ† **Best Model Overall: {better_model}!** ğŸ†\")\n",
        "\n",
        "# 7ï¸âƒ£ Evaluasi dan Perbandingan Model\n",
        "\n",
        "# âœ… Bersihkan NaN dari y_test sebelum evaluasi\n",
        "y_test_clean = y_test.dropna().reset_index(drop=True)\n",
        "y_pred_pytorch_clean = y_pred_pytorch[:len(y_test_clean)]\n",
        "y_pred_tf_clean = y_pred_tf[:len(y_test_clean)]\n",
        "\n",
        "# Menghitung metrik untuk kedua model\n",
        "metrics = [\"Akurasi\", \"Presisi\", \"Recall\", \"F1-Score\"]\n",
        "scores_pytorch = [\n",
        "    accuracy_score(y_test_clean, y_pred_pytorch_clean),  # Akurasi PyTorch\n",
        "    precision_score(y_test_clean, y_pred_pytorch_clean), # Presisi PyTorch\n",
        "    recall_score(y_test_clean, y_pred_pytorch_clean),    # Recall PyTorch\n",
        "    f1_score(y_test_clean, y_pred_pytorch_clean)        # F1-Score PyTorch\n",
        "]\n",
        "\n",
        "scores_tf = [\n",
        "    accuracy_score(y_test_clean, y_pred_tf_clean),  # Akurasi TensorFlow\n",
        "    precision_score(y_test_clean, y_pred_tf_clean), # Presisi TensorFlow\n",
        "    recall_score(y_test_clean, y_pred_tf_clean),    # Recall TensorFlow\n",
        "    f1_score(y_test_clean, y_pred_tf_clean)        # F1-Score TensorFlow\n",
        "]\n",
        "\n",
        "# Menampilkan hasil evaluasi\n",
        "print(\"\\n===============================\")\n",
        "print(\"ğŸ“Š Perbandingan Performa Model\")\n",
        "print(\"===============================\")\n",
        "\n",
        "for i in range(len(metrics)):\n",
        "    print(f\"{metrics[i]}:\")\n",
        "    print(f\"  ğŸŸ¢ PyTorch: {scores_pytorch[i]:.4f}\")\n",
        "    print(f\"  ğŸ”µ TensorFlow: {scores_tf[i]:.4f}\")\n",
        "    print()\n",
        "\n",
        "# ğŸ”¥ Menentukan model terbaik berdasarkan rata-rata skor\n",
        "rata_rata_pytorch = np.mean(scores_pytorch)\n",
        "rata_rata_tf = np.mean(scores_tf)\n",
        "\n",
        "if rata_rata_pytorch > rata_rata_tf:\n",
        "    model_terbaik = \"PyTorch\"\n",
        "else:\n",
        "    model_terbaik = \"TensorFlow\"\n",
        "\n",
        "# âœ¨ Menampilkan model terbaik berdasarkan metrik\n",
        "print(f\"\\nğŸ† **Model Terbaik: {model_terbaik}!** ğŸ†\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0FyFHI1qxVs",
        "outputId": "841915bc-beaa-4f13-cfd3-40e954b72b02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸŸ¢ Training PyTorch Model...\n",
            "Epoch [10/50], PyTorch Loss: 0.693147\n",
            "Epoch [20/50], PyTorch Loss: 0.693147\n",
            "Epoch [30/50], PyTorch Loss: 0.693143\n",
            "Epoch [40/50], PyTorch Loss: 0.693042\n",
            "Epoch [50/50], PyTorch Loss: 0.692721\n",
            "\n",
            "ğŸ”µ Training TensorFlow Model...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1206/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5029 - loss: nanEpoch [1] - Loss is NaN, replacing with 0.0\n",
            "Epoch [1] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5029 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "\u001b[1m1216/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5044 - loss: nanEpoch [2] - Loss is NaN, replacing with 0.0\n",
            "Epoch [2] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5044 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "\u001b[1m1198/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: nanEpoch [3] - Loss is NaN, replacing with 0.0\n",
            "Epoch [3] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5041 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "\u001b[1m1209/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: nanEpoch [4] - Loss is NaN, replacing with 0.0\n",
            "Epoch [4] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5055 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5027 - loss: nanEpoch [5] - Loss is NaN, replacing with 0.0\n",
            "Epoch [5] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5027 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5094 - loss: nanEpoch [6] - Loss is NaN, replacing with 0.0\n",
            "Epoch [6] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5094 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 7/50\n",
            "\u001b[1m1221/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5043 - loss: nanEpoch [7] - Loss is NaN, replacing with 0.0\n",
            "Epoch [7] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5044 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 8/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5019 - loss: nanEpoch [8] - Loss is NaN, replacing with 0.0\n",
            "Epoch [8] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5020 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 9/50\n",
            "\u001b[1m1216/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: nanEpoch [9] - Loss is NaN, replacing with 0.0\n",
            "Epoch [9] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 10/50\n",
            "\u001b[1m1214/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5003 - loss: nanEpoch [10] - Loss is NaN, replacing with 0.0\n",
            "Epoch [10] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5003 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 11/50\n",
            "\u001b[1m1214/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5078 - loss: nanEpoch [11] - Loss is NaN, replacing with 0.0\n",
            "Epoch [11] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5078 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 12/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: nanEpoch [12] - Loss is NaN, replacing with 0.0\n",
            "Epoch [12] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 13/50\n",
            "\u001b[1m1221/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: nanEpoch [13] - Loss is NaN, replacing with 0.0\n",
            "Epoch [13] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 14/50\n",
            "\u001b[1m1202/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5073 - loss: nanEpoch [14] - Loss is NaN, replacing with 0.0\n",
            "Epoch [14] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 15/50\n",
            "\u001b[1m1212/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5047 - loss: nanEpoch [15] - Loss is NaN, replacing with 0.0\n",
            "Epoch [15] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5047 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 16/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: nanEpoch [16] - Loss is NaN, replacing with 0.0\n",
            "Epoch [16] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 17/50\n",
            "\u001b[1m1213/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5112 - loss: nanEpoch [17] - Loss is NaN, replacing with 0.0\n",
            "Epoch [17] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5112 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 18/50\n",
            "\u001b[1m1210/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: nanEpoch [18] - Loss is NaN, replacing with 0.0\n",
            "Epoch [18] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5052 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 19/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5008 - loss: nanEpoch [19] - Loss is NaN, replacing with 0.0\n",
            "Epoch [19] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5008 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 20/50\n",
            "\u001b[1m1200/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: nanEpoch [20] - Loss is NaN, replacing with 0.0\n",
            "Epoch [20] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 21/50\n",
            "\u001b[1m1217/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5045 - loss: nanEpoch [21] - Loss is NaN, replacing with 0.0\n",
            "Epoch [21] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5045 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 22/50\n",
            "\u001b[1m1214/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: nanEpoch [22] - Loss is NaN, replacing with 0.0\n",
            "Epoch [22] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5054 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 23/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: nanEpoch [23] - Loss is NaN, replacing with 0.0\n",
            "Epoch [23] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 24/50\n",
            "\u001b[1m1217/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: nanEpoch [24] - Loss is NaN, replacing with 0.0\n",
            "Epoch [24] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 25/50\n",
            "\u001b[1m1210/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: nanEpoch [25] - Loss is NaN, replacing with 0.0\n",
            "Epoch [25] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5104 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 26/50\n",
            "\u001b[1m1208/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5080 - loss: nanEpoch [26] - Loss is NaN, replacing with 0.0\n",
            "Epoch [26] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5080 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 27/50\n",
            "\u001b[1m1197/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: nanEpoch [27] - Loss is NaN, replacing with 0.0\n",
            "Epoch [27] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 28/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5066 - loss: nanEpoch [28] - Loss is NaN, replacing with 0.0\n",
            "Epoch [28] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 29/50\n",
            "\u001b[1m1201/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5019 - loss: nanEpoch [29] - Loss is NaN, replacing with 0.0\n",
            "Epoch [29] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5020 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 30/50\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5079 - loss: nanEpoch [30] - Loss is NaN, replacing with 0.0\n",
            "Epoch [30] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5079 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 31/50\n",
            "\u001b[1m1212/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4991 - loss: nanEpoch [31] - Loss is NaN, replacing with 0.0\n",
            "Epoch [31] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4991 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 32/50\n",
            "\u001b[1m1207/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: nanEpoch [32] - Loss is NaN, replacing with 0.0\n",
            "Epoch [32] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 33/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: nanEpoch [33] - Loss is NaN, replacing with 0.0\n",
            "Epoch [33] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "\u001b[1m1211/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: nanEpoch [34] - Loss is NaN, replacing with 0.0\n",
            "Epoch [34] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "\u001b[1m1207/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nanEpoch [35] - Loss is NaN, replacing with 0.0\n",
            "Epoch [35] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "\u001b[1m1212/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5053 - loss: nanEpoch [36] - Loss is NaN, replacing with 0.0\n",
            "Epoch [36] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5053 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "\u001b[1m1212/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: nanEpoch [37] - Loss is NaN, replacing with 0.0\n",
            "Epoch [37] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "\u001b[1m1199/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5066 - loss: nanEpoch [38] - Loss is NaN, replacing with 0.0\n",
            "Epoch [38] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5021 - loss: nanEpoch [39] - Loss is NaN, replacing with 0.0\n",
            "Epoch [39] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5065 - loss: nanEpoch [40] - Loss is NaN, replacing with 0.0\n",
            "Epoch [40] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5065 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "\u001b[1m1202/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5103 - loss: nanEpoch [41] - Loss is NaN, replacing with 0.0\n",
            "Epoch [41] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5103 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 42/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: nanEpoch [42] - Loss is NaN, replacing with 0.0\n",
            "Epoch [42] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5089 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 43/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: nanEpoch [43] - Loss is NaN, replacing with 0.0\n",
            "Epoch [43] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 44/50\n",
            "\u001b[1m1202/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: nanEpoch [44] - Loss is NaN, replacing with 0.0\n",
            "Epoch [44] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5032 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 45/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: nanEpoch [45] - Loss is NaN, replacing with 0.0\n",
            "Epoch [45] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: nanEpoch [46] - Loss is NaN, replacing with 0.0\n",
            "Epoch [46] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "\u001b[1m1208/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5035 - loss: nanEpoch [47] - Loss is NaN, replacing with 0.0\n",
            "Epoch [47] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5036 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "\u001b[1m1211/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: nanEpoch [48] - Loss is NaN, replacing with 0.0\n",
            "Epoch [48] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5041 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5008 - loss: nanEpoch [49] - Loss is NaN, replacing with 0.0\n",
            "Epoch [49] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5008 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "\u001b[1m1211/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: nanEpoch [50] - Loss is NaN, replacing with 0.0\n",
            "Epoch [50] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "\u001b[1m306/306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "===============================\n",
            "ğŸ“Š Model Performance Comparison\n",
            "===============================\n",
            "Accuracy:\n",
            "  ğŸŸ¢ PyTorch: 0.7355\n",
            "  ğŸ”µ TensorFlow: 0.7596\n",
            "\n",
            "Precision:\n",
            "  ğŸŸ¢ PyTorch: 0.2861\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "Recall:\n",
            "  ğŸŸ¢ PyTorch: 0.0672\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "F1-Score:\n",
            "  ğŸŸ¢ PyTorch: 0.1089\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "\n",
            "ğŸ† **Best Model Overall: PyTorch!** ğŸ†\n",
            "\n",
            "===============================\n",
            "ğŸ“Š Perbandingan Performa Model\n",
            "===============================\n",
            "Akurasi:\n",
            "  ğŸŸ¢ PyTorch: 0.7355\n",
            "  ğŸ”µ TensorFlow: 0.7596\n",
            "\n",
            "Presisi:\n",
            "  ğŸŸ¢ PyTorch: 0.2861\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "Recall:\n",
            "  ğŸŸ¢ PyTorch: 0.0672\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "F1-Score:\n",
            "  ğŸŸ¢ PyTorch: 0.1089\n",
            "  ğŸ”µ TensorFlow: 0.0000\n",
            "\n",
            "\n",
            "ğŸ† **Model Terbaik: PyTorch!** ğŸ†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Alasan PyTorch menang\n",
        "Kontrol Penuh terhadap Training Loop\n",
        "ğŸ”¹ Di PyTorch, kita secara eksplisit mengontrol forward pass, backward pass, dan optimasi.\n",
        "ğŸ”¹ TensorFlow (Keras) menggunakan API tingkat tinggi, yang otomatis melakukan training dengan model.fit().\n",
        "\n",
        "ğŸ‘‰ Dalam kasus dataset ini, PyTorch mungkin menang karena kita memiliki lebih banyak fleksibilitas dalam mengatur training loop, termasuk teknik seperti gradient clipping.\n",
        "ğŸ‘‰ Jika dataset memiliki pola yang lebih kompleks atau membutuhkan penyesuaian bobot secara manual, PyTorch sering lebih unggul.\n",
        "\n",
        "2ï¸âƒ£ Penanganan Outlier dan Normalisasi Data\n",
        "ğŸ”¹ PyTorch menggunakan torch.clamp() untuk mencegah nilai ekstrem (exploding gradients).\n",
        "ğŸ”¹ TensorFlow tidak secara otomatis menerapkan clipping pada output layer, sehingga bisa terjadi ketidakstabilan dalam training.\n",
        "\n",
        "ğŸ‘‰ Jika dataset ini memiliki outlier atau distribusi fitur yang tidak merata, model PyTorch mungkin lebih stabil karena sudah menerapkan clipping secara eksplisit.\n",
        "\n",
        "3ï¸âƒ£ Efisiensi Penggunaan Memori & Gradien\n",
        "ğŸ”¹ Di PyTorch, kita mengatur sendiri zero_grad() setiap epoch, sehingga gradien tidak menumpuk.\n",
        "ğŸ”¹ TensorFlow otomatis mengatur ulang gradien, tetapi bisa mengalami overfitting lebih cepat dalam beberapa kasus.\n",
        "\n",
        "ğŸ‘‰ Jika PyTorch menang, itu bisa jadi karena PyTorch lebih efisien dalam memperbarui bobot tanpa gradien yang \"bocor\" atau tidak ter-reset dengan baik.\n",
        "\n",
        "4ï¸âƒ£ Keuntungan dari BCEWithLogitsLoss di PyTorch\n",
        "ğŸ”¹ Di PyTorch, kita menggunakan BCEWithLogitsLoss() yang lebih stabil dibanding binary_crossentropy di TensorFlow.\n",
        "ğŸ”¹ Loss function ini menggabungkan sigmoid + binary cross-entropy dalam satu operasi matematis, menghindari numerical instability.\n",
        "\n",
        "ğŸ‘‰ Jika PyTorch menang, ini bisa jadi karena loss function-nya lebih stabil dibandingkan dengan TensorFlow, yang masih memisahkan sigmoid dan binary cross-entropy.\n",
        "\n",
        "ğŸ¯ Kesimpulan: Kapan PyTorch Bisa Lebih Baik?\n",
        "PyTorch lebih unggul dalam kasus ini jika:\n",
        "âœ… Dataset memiliki outlier atau distribusi yang sulit, sehingga clipping dan normalisasi yang lebih eksplisit di PyTorch membantu stabilitas.\n",
        "âœ… Model memerlukan kontrol penuh atas training loop, sehingga pengaturan manual di PyTorch memberikan hasil lebih baik.\n",
        "âœ… Training lebih efisien karena gradien direset secara eksplisit dengan zero_grad(), sehingga model tidak mengalami \"gradien bocor\".\n",
        "âœ… Loss function yang lebih stabil (BCEWithLogitsLoss()) dibanding binary crossentropy di TensorFlow, terutama jika ada nilai ekstrem di dataset.\n",
        "\n",
        "\n",
        "### Metrik Evaluasi\n",
        "## 1. Recall (Sensitivitas)\n",
        "\n",
        "**Definisi:**\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- **TP (True Positive)**: Model memprediksi positif, dan kenyataannya memang positif.  \n",
        "- **FN (False Negative)**: Model memprediksi negatif, padahal sebenarnya positif.\n",
        "\n",
        "**Penjelasan:**\n",
        "- *Recall* mengukur seberapa banyak model berhasil menemukan kasus positif yang sebenarnya.  \n",
        "- Semakin tinggi *Recall*, semakin sedikit kasus positif yang lolos (tidak terdeteksi).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Precision\n",
        "\n",
        "**Definisi:**\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "- **TP (True Positive)**: Model memprediksi positif, dan kenyataannya memang positif.  \n",
        "- **FP (False Positive)**: Model memprediksi positif, padahal sebenarnya negatif.\n",
        "\n",
        "**Penjelasan:**\n",
        "- *Precision* mengukur ketepatan model saat memprediksi kelas positif.  \n",
        "- Semakin tinggi *Precision*, semakin sedikit model memberikan prediksi positif yang keliru.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. F1-Score\n",
        "\n",
        "**Definisi:**\n",
        "$$\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "**Penjelasan:**\n",
        "- *F1-Score* adalah rata-rata harmonis antara *Precision* dan *Recall*.  \n",
        "- Nilai F1 yang tinggi berarti keseimbangan yang baik antara *Precision* dan *Recall*.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ROC Curve (Receiver Operating Characteristic)\n",
        "\n",
        "**Konsep Dasar:**\n",
        "- *ROC Curve* adalah grafik yang memplot **True Positive Rate (TPR)** terhadap **False Positive Rate (FPR)** di berbagai nilai ambang (*threshold*).  \n",
        "\n",
        "### 4.1 True Positive Rate (TPR) / Recall\n",
        "\n",
        "$$\n",
        "\\text{TPR} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- Ini sama dengan *Recall*.\n",
        "\n",
        "### 4.2 False Positive Rate (FPR)\n",
        "\n",
        "$$\n",
        "\\text{FPR} = \\frac{FP}{FP + TN}\n",
        "$$\n",
        "\n",
        "- **FP (False Positive)**: Model memprediksi positif, padahal sebenarnya negatif.  \n",
        "- **TN (True Negative)**: Model memprediksi negatif, dan kenyataannya memang negatif.\n",
        "\n",
        "**Penjelasan:**\n",
        "- Setiap titik pada kurva ROC menggambarkan kombinasi (TPR, FPR) untuk nilai ambang tertentu (misalnya 0.5, 0.6, dst.).  \n",
        "- Dengan menggeser ambang prediksi (threshold), model akan menghasilkan pasangan (TPR, FPR) yang berbeda.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. AUC (Area Under the Curve)\n",
        "\n",
        "**Konsep Dasar:**\n",
        "- *AUC* adalah luas area di bawah kurva ROC (ROC Curve).  \n",
        "- Semakin besar nilai AUC (mendekati 1), semakin baik model dalam membedakan kelas positif dan negatif.\n",
        "\n",
        "**Interpretasi:**\n",
        "- AUC = 0.5 menunjukkan model sama saja seperti menebak secara acak.  \n",
        "- AUC > 0.9 umumnya menandakan model yang sangat baik dalam membedakan kelas.\n",
        "\n",
        "**Rumus Umum AUC (Secara Konseptual):**\n",
        "Walaupun secara praktis AUC sering dihitung dengan metode numerik (trapezoidal rule), konsep dasarnya dapat diartikan sebagai:\n",
        "\n",
        "$$\n",
        "\\text{AUC} = \\int_{0}^{1} \\text{TPR}(\\text{FPR}) \\, d(\\text{FPR})\n",
        "$$\n",
        "\n",
        "- Di mana \\(\\text{TPR}(\\text{FPR})\\) adalah fungsi TPR yang bergantung pada FPR ketika threshold bervariasi dari 0 ke 1.\n",
        "\n",
        "---\n",
        "\n",
        "## Hubungan dengan Heart Disease\n",
        "\n",
        "1. **Heart Disease**  \n",
        "   - **Recall** tinggi berarti model jarang melewatkan pasien yang sebenarnya memiliki penyakit jantung (FN rendah).  \n",
        "   - **Precision** tinggi berarti jika model bilang \"ada penyakit\", kemungkinan besar memang benar.  \n",
        "   - **F1-Score** digunakan jika kita ingin keseimbangan antara *Precision* dan *Recall*.  \n",
        "   - **ROC Curve & AUC** membantu melihat seberapa baik model membedakan antara \"ada penyakit\" (1) dan \"tidak ada penyakit\" (0) di berbagai threshold.\n",
        "\n",
        "---\n",
        "\n",
        "**Ringkasan:**\n",
        "- *Recall* menekankan deteksi positif yang benar (penting jika kita tak ingin melewatkan kasus penyakit atau kualitas buruk).  \n",
        "- *Precision* menekankan ketepatan prediksi positif (penting jika kita tak ingin terlalu sering salah mengira negatif sebagai positif).  \n",
        "- *F1-Score* menyeimbangkan keduanya.  \n",
        "- *ROC Curve* menampilkan perbandingan TPR vs FPR di berbagai ambang.  \n",
        "- *AUC* mengukur â€œkualitasâ€ pemisahan kelas oleh model secara keseluruhan.\n"
      ],
      "metadata": {
        "id": "6d3k9kPRC8Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiWwrt7gydv",
        "outputId": "0c86e326-8f3e-428c-b88d-80b2fcaf3fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio tensorflow scikit-learn pandas numpy matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ivu2pMo9rV6V",
        "outputId": "8006714c-7d43-44ae-8eb6-bed0c405a743"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "74b66ea5b3c140a1a531f0010d515717"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}