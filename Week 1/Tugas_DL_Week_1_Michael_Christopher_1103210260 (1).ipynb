{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWjRB1cif12c",
        "outputId": "ff995a7c-1aa9-414d-950b-b5f72e3b5d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-0b3daf761dd7>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 180.9966\n",
            "Epoch [20/50], Loss: 12.3951\n",
            "Epoch [30/50], Loss: 4.9354\n",
            "Epoch [40/50], Loss: 2.6665\n",
            "Epoch [50/50], Loss: 1.7335\n",
            "\n",
            "Evaluasi Model:\n",
            "Mean Squared Error (MSE): 2.9286\n",
            "Root Mean Squared Error (RMSE): 1.7113\n",
            "R-Squared (RÂ²): -9.7971\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Cek apakah CUDA tersedia\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Infrared.csv\")\n",
        "\n",
        "# Mengisi nilai yang hilang dengan median\n",
        "df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
        "\n",
        "# Encoding variabel kategorikal\n",
        "label_encoders = {}\n",
        "categorical_cols = [\"Gender\", \"Age\", \"Ethnicity\"]\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = df.columns.difference([\"aveOralM\"])  # Semua fitur kecuali target\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X = torch.tensor(df[numerical_cols].values, dtype=torch.float32).to(device)\n",
        "y = torch.tensor(df[\"aveOralM\"].values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Membagi data menjadi training (80%) dan testing (20%)\n",
        "train_size = int(0.8 * len(df))\n",
        "test_size = len(df) - train_size\n",
        "dataset = TensorDataset(X, y)\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Membuat DataLoader untuk batch processing\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Definisi model Deep Learning\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Inisialisasi model, loss function, dan optimizer\n",
        "input_size = X.shape[1]\n",
        "model = NeuralNet(input_size).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training model\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Print setiap 10 epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluasi model\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        predictions = model(batch_X)\n",
        "        y_true.extend(batch_y.cpu().numpy())\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\nEvaluasi Model:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-Squared (RÂ²): {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Infrared.csv\")\n",
        "\n",
        "# Mengisi nilai yang hilang dengan median\n",
        "df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
        "\n",
        "# Encoding variabel kategorikal\n",
        "label_encoders = {}\n",
        "categorical_cols = [\"Gender\", \"Age\", \"Ethnicity\"]\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = df.columns.difference([\"aveOralM\"])  # Semua fitur kecuali target\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X = df[numerical_cols].values\n",
        "y = df[\"aveOralM\"].values\n",
        "\n",
        "# Membagi data menjadi training (80%) dan testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membangun model dengan TensorFlow (Keras)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # Output layer untuk regresi\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n",
        "\n",
        "# Training model\n",
        "num_epochs = 50\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluasi model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nEvaluasi Model:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-Squared (RÂ²): {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdYAkkKgX5yi",
        "outputId": "ba411131-fc10-435e-ea7f-0927c0815130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e76f142cd14d>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Distance\"].fillna(df[\"Distance\"].median(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1352.0593 - mse: 1352.0593 - val_loss: 1236.2085 - val_mse: 1236.2085\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1173.6807 - mse: 1173.6807 - val_loss: 983.8384 - val_mse: 983.8384\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 915.6106 - mse: 915.6106 - val_loss: 627.9178 - val_mse: 627.9178\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603.3255 - mse: 603.3255 - val_loss: 474.0075 - val_mse: 474.0075\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476.3400 - mse: 476.3400 - val_loss: 459.0061 - val_mse: 459.0061\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 441.5398 - mse: 441.5398 - val_loss: 397.2764 - val_mse: 397.2764\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 368.5170 - mse: 368.5170 - val_loss: 342.1775 - val_mse: 342.1775\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 299.7586 - mse: 299.7586 - val_loss: 273.5806 - val_mse: 273.5806\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 239.8593 - mse: 239.8593 - val_loss: 213.6297 - val_mse: 213.6297\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179.9853 - mse: 179.9853 - val_loss: 172.7796 - val_mse: 172.7796\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131.8212 - mse: 131.8212 - val_loss: 133.8642 - val_mse: 133.8642\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94.0109 - mse: 94.0109 - val_loss: 98.3987 - val_mse: 98.3987\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 67.8378 - mse: 67.8378 - val_loss: 81.1222 - val_mse: 81.1222\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.8635 - mse: 48.8635 - val_loss: 67.4974 - val_mse: 67.4974\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.5934 - mse: 36.5934 - val_loss: 57.1703 - val_mse: 57.1703\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7996 - mse: 29.7996 - val_loss: 48.5748 - val_mse: 48.5748\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4063 - mse: 27.4063 - val_loss: 43.6308 - val_mse: 43.6308\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.5166 - mse: 22.5166 - val_loss: 39.0458 - val_mse: 39.0458\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.4456 - mse: 20.4456 - val_loss: 35.3697 - val_mse: 35.3697\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19.2850 - mse: 19.2850 - val_loss: 31.2286 - val_mse: 31.2286\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2167 - mse: 16.2167 - val_loss: 29.7012 - val_mse: 29.7012\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.5957 - mse: 15.5957 - val_loss: 26.7366 - val_mse: 26.7366\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.0641 - mse: 14.0641 - val_loss: 24.2799 - val_mse: 24.2799\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.0433 - mse: 13.0433 - val_loss: 22.1594 - val_mse: 22.1594\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.0744 - mse: 12.0744 - val_loss: 21.4208 - val_mse: 21.4208\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.6800 - mse: 11.6800 - val_loss: 19.5321 - val_mse: 19.5321\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3621 - mse: 10.3621 - val_loss: 18.0701 - val_mse: 18.0701\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.2544 - mse: 10.2544 - val_loss: 17.5997 - val_mse: 17.5997\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4199 - mse: 9.4199 - val_loss: 16.5474 - val_mse: 16.5474\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2042 - mse: 8.2042 - val_loss: 15.5372 - val_mse: 15.5372\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7140 - mse: 7.7140 - val_loss: 14.3928 - val_mse: 14.3928\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5602 - mse: 7.5602 - val_loss: 13.8642 - val_mse: 13.8642\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1339 - mse: 7.1339 - val_loss: 13.1419 - val_mse: 13.1419\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8358 - mse: 6.8358 - val_loss: 12.3586 - val_mse: 12.3586\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5849 - mse: 6.5849 - val_loss: 11.6115 - val_mse: 11.6115\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4249 - mse: 6.4249 - val_loss: 11.2511 - val_mse: 11.2511\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3865 - mse: 5.3865 - val_loss: 10.8945 - val_mse: 10.8945\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8904 - mse: 5.8904 - val_loss: 10.1360 - val_mse: 10.1360\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0205 - mse: 5.0205 - val_loss: 9.9144 - val_mse: 9.9144\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6848 - mse: 4.6848 - val_loss: 9.4696 - val_mse: 9.4696\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1039 - mse: 5.1039 - val_loss: 9.0090 - val_mse: 9.0090\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.0402 - mse: 4.0402 - val_loss: 8.7949 - val_mse: 8.7949\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5846 - mse: 4.5846 - val_loss: 8.1697 - val_mse: 8.1697\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5209 - mse: 4.5209 - val_loss: 8.0087 - val_mse: 8.0087\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9043 - mse: 3.9043 - val_loss: 7.5973 - val_mse: 7.5973\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8576 - mse: 3.8576 - val_loss: 7.3136 - val_mse: 7.3136\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8266 - mse: 3.8266 - val_loss: 7.3324 - val_mse: 7.3324\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7013 - mse: 3.7013 - val_loss: 6.8158 - val_mse: 6.8158\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3440 - mse: 3.3440 - val_loss: 6.6798 - val_mse: 6.6798\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1625 - mse: 3.1625 - val_loss: 6.2900 - val_mse: 6.2900\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\n",
            "Evaluasi Model:\n",
            "Mean Squared Error (MSE): 5.0543\n",
            "Root Mean Squared Error (RMSE): 2.2482\n",
            "R-Squared (RÂ²): -23.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/income (1).csv\")\n",
        "\n",
        "# Tampilkan beberapa baris pertama\n",
        "print(df.head())\n",
        "\n",
        "# Cek informasi dataset\n",
        "print(df.info())\n",
        "\n",
        "# Hapus missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_columns:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Normalisasi fitur numerik\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Split dataset menjadi train-test\n",
        "X = df.drop(columns=['income'])  # Asumsi target adalah 'income'\n",
        "y = df['income']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFHhj_xCeq7Z",
        "outputId": "40fc2326-457c-4dd2-954c-b8187fca8333"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age         workclass  fnlwgt  education  education-num  \\\n",
            "0   39         State-gov   77516  Bachelors             13   \n",
            "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
            "2   38           Private  215646    HS-grad              9   \n",
            "3   53           Private  234721       11th              7   \n",
            "4   28           Private  338409  Bachelors             13   \n",
            "\n",
            "       marital-status         occupation   relationship   race     sex  \\\n",
            "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
            "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
            "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
            "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
            "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
            "\n",
            "   capital-gain  capital-loss  hours-per-week native-country income  \n",
            "0          2174             0              40  United-States  <=50K  \n",
            "1             0             0              13  United-States  <=50K  \n",
            "2             0             0              40  United-States  <=50K  \n",
            "3             0             0              40  United-States  <=50K  \n",
            "4             0             0              40           Cuba  <=50K  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             48842 non-null  int64 \n",
            " 1   workclass       47879 non-null  object\n",
            " 2   fnlwgt          48842 non-null  int64 \n",
            " 3   education       48842 non-null  object\n",
            " 4   education-num   48842 non-null  int64 \n",
            " 5   marital-status  48842 non-null  object\n",
            " 6   occupation      47876 non-null  object\n",
            " 7   relationship    48842 non-null  object\n",
            " 8   race            48842 non-null  object\n",
            " 9   sex             48842 non-null  object\n",
            " 10  capital-gain    48842 non-null  int64 \n",
            " 11  capital-loss    48842 non-null  int64 \n",
            " 12  hours-per-week  48842 non-null  int64 \n",
            " 13  native-country  48568 non-null  object\n",
            " 14  income          48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoder.fit_transform(df[col])\n",
            "<ipython-input-1-ab407d908480>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£ Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 2ï¸âƒ£ Load Dataset (Keep NaN)\n",
        "file_path = \"/content/income (1).csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove extra spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Convert target 'income' to 0 and 1\n",
        "df[\"income\"] = df[\"income\"].str.strip()\n",
        "df[\"income\"] = df[\"income\"].map({\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "# Encode categorical features\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Split dataset\n",
        "X = df.drop(columns=[\"income\"])\n",
        "y = df[\"income\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data (Keep NaN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# =====================================\n",
        "# ğŸŸ¢  PyTorch Section ğŸŸ¢\n",
        "# =====================================\n",
        "\n",
        "# Convert to PyTorch Tensors (Keep NaN but handle it for training)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Replace NaN in tensors with zeros for training\n",
        "X_train_tensor = torch.nan_to_num(X_train_tensor, nan=0.0)\n",
        "y_train_tensor = torch.nan_to_num(y_train_tensor, nan=0.0)\n",
        "\n",
        "# Define PyTorch Model\n",
        "class IncomeModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IncomeModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize PyTorch Model (Ensure float32)\n",
        "model = IncomeModel().float()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training PyTorch Model (Ignore NaN in Loss)\n",
        "print(\"\\nğŸŸ¢ Training PyTorch Model...\")\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)  # Ensure float32\n",
        "\n",
        "    # Clamp outputs to prevent log(0) issue\n",
        "    outputs = torch.clamp(outputs, min=1e-7, max=1 - 1e-7)\n",
        "\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Ignore NaN values in loss\n",
        "    if torch.isnan(loss):\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss contains NaN, replacing with 0.0\")\n",
        "        loss = torch.nan_to_num(loss, nan=0.0)\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], PyTorch Loss: {loss.item():.6f}\")\n",
        "\n",
        "# Evaluate PyTorch Model\n",
        "y_pred_tensor = torch.sigmoid(model(X_test_tensor)).detach().numpy()\n",
        "y_pred_pytorch = (y_pred_tensor > 0.5).astype(int)\n",
        "\n",
        "# =====================================\n",
        "# ğŸ”µ  TensorFlow (Keras) Section ğŸ”µ\n",
        "# =====================================\n",
        "\n",
        "# Define TensorFlow Model\n",
        "model_tf = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile TensorFlow Model\n",
        "model_tf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Custom Callback to Handle NaN Loss in TensorFlow\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if np.isnan(logs[\"loss\"]):\n",
        "            print(f\"Epoch [{epoch+1}] - Loss is NaN, replacing with 0.0\")\n",
        "            logs[\"loss\"] = 0.0\n",
        "        if \"val_loss\" in logs and np.isnan(logs[\"val_loss\"]):\n",
        "            print(f\"Epoch [{epoch+1}] - Val Loss is NaN, replacing with 0.0\")\n",
        "            logs[\"val_loss\"] = 0.0\n",
        "\n",
        "# Train TensorFlow Model\n",
        "print(\"\\nğŸ”µ Training TensorFlow Model...\")\n",
        "model_tf.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=[CustomCallback()])\n",
        "\n",
        "# Evaluate TensorFlow Model\n",
        "y_pred_tf = (model_tf.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# =====================================\n",
        "# ğŸ“Š Model Evaluation (Fix NaN in y_test)\n",
        "# =====================================\n",
        "\n",
        "print(\"\\n===============================\")\n",
        "print(\"ğŸ“Š Final Evaluation of Both Models\")\n",
        "print(\"===============================\")\n",
        "\n",
        "# âœ… Fix NaN in y_test before evaluation\n",
        "y_test_clean = y_test.dropna().reset_index(drop=True)\n",
        "y_pred_pytorch_clean = y_pred_pytorch[:len(y_test_clean)]\n",
        "y_pred_tf_clean = y_pred_tf[:len(y_test_clean)]\n",
        "\n",
        "print(\"\\nğŸŸ¢ PyTorch Model Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_clean, y_pred_pytorch_clean):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_clean, y_pred_pytorch_clean):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_clean, y_pred_pytorch_clean):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_clean, y_pred_pytorch_clean):.4f}\")\n",
        "\n",
        "print(\"\\nğŸ”µ TensorFlow Model Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_clean, y_pred_tf_clean):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_clean, y_pred_tf_clean):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_clean, y_pred_tf_clean):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_clean, y_pred_tf_clean):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0FyFHI1qxVs",
        "outputId": "70ce3e10-f2cb-421f-a309-00e0eac3b851"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸŸ¢ Training PyTorch Model...\n",
            "Epoch [10/50], PyTorch Loss: 0.693147\n",
            "Epoch [20/50], PyTorch Loss: 0.693147\n",
            "Epoch [30/50], PyTorch Loss: 0.693147\n",
            "Epoch [40/50], PyTorch Loss: 0.693147\n",
            "Epoch [50/50], PyTorch Loss: 0.693147\n",
            "\n",
            "ğŸ”µ Training TensorFlow Model...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1208/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5087 - loss: nanEpoch [1] - Loss is NaN, replacing with 0.0\n",
            "Epoch [1] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5087 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "\u001b[1m1213/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: nanEpoch [2] - Loss is NaN, replacing with 0.0\n",
            "Epoch [2] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5072 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "\u001b[1m1202/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: nanEpoch [3] - Loss is NaN, replacing with 0.0\n",
            "Epoch [3] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5040 - loss: nanEpoch [4] - Loss is NaN, replacing with 0.0\n",
            "Epoch [4] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5040 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: nanEpoch [5] - Loss is NaN, replacing with 0.0\n",
            "Epoch [5] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5061 - loss: nanEpoch [6] - Loss is NaN, replacing with 0.0\n",
            "Epoch [6] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 7/50\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: nanEpoch [7] - Loss is NaN, replacing with 0.0\n",
            "Epoch [7] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 8/50\n",
            "\u001b[1m1209/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5038 - loss: nanEpoch [8] - Loss is NaN, replacing with 0.0\n",
            "Epoch [8] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5038 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 9/50\n",
            "\u001b[1m1203/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: nanEpoch [9] - Loss is NaN, replacing with 0.0\n",
            "Epoch [9] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5091 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 10/50\n",
            "\u001b[1m1213/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: nanEpoch [10] - Loss is NaN, replacing with 0.0\n",
            "Epoch [10] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 11/50\n",
            "\u001b[1m1209/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5098 - loss: nanEpoch [11] - Loss is NaN, replacing with 0.0\n",
            "Epoch [11] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5098 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 12/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5085 - loss: nanEpoch [12] - Loss is NaN, replacing with 0.0\n",
            "Epoch [12] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 13/50\n",
            "\u001b[1m1202/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5011 - loss: nanEpoch [13] - Loss is NaN, replacing with 0.0\n",
            "Epoch [13] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5012 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 14/50\n",
            "\u001b[1m1209/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: nanEpoch [14] - Loss is NaN, replacing with 0.0\n",
            "Epoch [14] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5070 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 15/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: nanEpoch [15] - Loss is NaN, replacing with 0.0\n",
            "Epoch [15] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5093 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 16/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: nanEpoch [16] - Loss is NaN, replacing with 0.0\n",
            "Epoch [16] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5040 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 17/50\n",
            "\u001b[1m1204/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: nanEpoch [17] - Loss is NaN, replacing with 0.0\n",
            "Epoch [17] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 18/50\n",
            "\u001b[1m1199/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5033 - loss: nanEpoch [18] - Loss is NaN, replacing with 0.0\n",
            "Epoch [18] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5033 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 19/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5103 - loss: nanEpoch [19] - Loss is NaN, replacing with 0.0\n",
            "Epoch [19] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5103 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 20/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: nanEpoch [20] - Loss is NaN, replacing with 0.0\n",
            "Epoch [20] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 21/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: nanEpoch [21] - Loss is NaN, replacing with 0.0\n",
            "Epoch [21] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5022 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 22/50\n",
            "\u001b[1m1221/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: nanEpoch [22] - Loss is NaN, replacing with 0.0\n",
            "Epoch [22] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 23/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: nanEpoch [23] - Loss is NaN, replacing with 0.0\n",
            "Epoch [23] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 24/50\n",
            "\u001b[1m1206/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nanEpoch [24] - Loss is NaN, replacing with 0.0\n",
            "Epoch [24] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 25/50\n",
            "\u001b[1m1219/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: nanEpoch [25] - Loss is NaN, replacing with 0.0\n",
            "Epoch [25] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 26/50\n",
            "\u001b[1m1205/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: nanEpoch [26] - Loss is NaN, replacing with 0.0\n",
            "Epoch [26] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 27/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: nanEpoch [27] - Loss is NaN, replacing with 0.0\n",
            "Epoch [27] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5077 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 28/50\n",
            "\u001b[1m1214/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5069 - loss: nanEpoch [28] - Loss is NaN, replacing with 0.0\n",
            "Epoch [28] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 29/50\n",
            "\u001b[1m1208/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: nanEpoch [29] - Loss is NaN, replacing with 0.0\n",
            "Epoch [29] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5056 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 30/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5053 - loss: nanEpoch [30] - Loss is NaN, replacing with 0.0\n",
            "Epoch [30] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5053 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 31/50\n",
            "\u001b[1m1214/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: nanEpoch [31] - Loss is NaN, replacing with 0.0\n",
            "Epoch [31] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 32/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5083 - loss: nanEpoch [32] - Loss is NaN, replacing with 0.0\n",
            "Epoch [32] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5083 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 33/50\n",
            "\u001b[1m1207/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5079 - loss: nanEpoch [33] - Loss is NaN, replacing with 0.0\n",
            "Epoch [33] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5079 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "\u001b[1m1212/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: nanEpoch [34] - Loss is NaN, replacing with 0.0\n",
            "Epoch [34] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "\u001b[1m1217/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5019 - loss: nanEpoch [35] - Loss is NaN, replacing with 0.0\n",
            "Epoch [35] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5019 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: nanEpoch [36] - Loss is NaN, replacing with 0.0\n",
            "Epoch [36] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5054 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "\u001b[1m1204/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: nanEpoch [37] - Loss is NaN, replacing with 0.0\n",
            "Epoch [37] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5035 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "\u001b[1m1220/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: nanEpoch [38] - Loss is NaN, replacing with 0.0\n",
            "Epoch [38] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5109 - loss: nanEpoch [39] - Loss is NaN, replacing with 0.0\n",
            "Epoch [39] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5109 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "\u001b[1m1208/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5057 - loss: nanEpoch [40] - Loss is NaN, replacing with 0.0\n",
            "Epoch [40] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5057 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "\u001b[1m1210/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5036 - loss: nanEpoch [41] - Loss is NaN, replacing with 0.0\n",
            "Epoch [41] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5036 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 42/50\n",
            "\u001b[1m1198/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5068 - loss: nanEpoch [42] - Loss is NaN, replacing with 0.0\n",
            "Epoch [42] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5068 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 43/50\n",
            "\u001b[1m1218/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: nanEpoch [43] - Loss is NaN, replacing with 0.0\n",
            "Epoch [43] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5061 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 44/50\n",
            "\u001b[1m1213/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5060 - loss: nanEpoch [44] - Loss is NaN, replacing with 0.0\n",
            "Epoch [44] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5060 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 45/50\n",
            "\u001b[1m1215/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: nanEpoch [45] - Loss is NaN, replacing with 0.0\n",
            "Epoch [45] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5115 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "\u001b[1m1217/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5066 - loss: nanEpoch [46] - Loss is NaN, replacing with 0.0\n",
            "Epoch [46] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "\u001b[1m1204/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5097 - loss: nanEpoch [47] - Loss is NaN, replacing with 0.0\n",
            "Epoch [47] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5096 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "\u001b[1m1206/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5053 - loss: nanEpoch [48] - Loss is NaN, replacing with 0.0\n",
            "Epoch [48] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5053 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "\u001b[1m1221/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5061 - loss: nanEpoch [49] - Loss is NaN, replacing with 0.0\n",
            "Epoch [49] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "\u001b[1m1221/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: nanEpoch [50] - Loss is NaN, replacing with 0.0\n",
            "Epoch [50] - Val Loss is NaN, replacing with 0.0\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: nan - val_accuracy: 0.5053 - val_loss: 0.0000e+00\n",
            "\u001b[1m306/306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\n",
            "===============================\n",
            "ğŸ“Š Final Evaluation of Both Models\n",
            "===============================\n",
            "\n",
            "ğŸŸ¢ PyTorch Model Results:\n",
            "Accuracy: 0.7596\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n",
            "\n",
            "ğŸ”µ TensorFlow Model Results:\n",
            "Accuracy: 0.7596\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiWwrt7gydv",
        "outputId": "0c86e326-8f3e-428c-b88d-80b2fcaf3fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio tensorflow scikit-learn pandas numpy matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ivu2pMo9rV6V",
        "outputId": "8006714c-7d43-44ae-8eb6-bed0c405a743"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "74b66ea5b3c140a1a531f0010d515717"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}